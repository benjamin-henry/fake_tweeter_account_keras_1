{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20e9fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2515ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data[\"fake\"]  = pd.read_csv(\"DATASET/fusers.csv\")\n",
    "data[\"legit\"] = pd.read_csv(\"DATASET/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e992e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"] = data[\"legit\"].drop([\"id\", \"name\", \"screen_name\", \"statuses_count\", \"created_at\", \"lang\", \"location\", \"geo_enabled\", \"default_profile_image\", \"profile_image_url\", \"profile_banner_url\", \"profile_use_background_image\", \"profile_background_image_url_https\", \"profile_text_color\", \"profile_image_url_https\", \"profile_sidebar_border_color\", \"profile_background_tile\", \"profile_sidebar_fill_color\", \"profile_background_image_url\", \"profile_background_color\", \"profile_link_color\", \"utc_offset\", \"protected\", \"verified\", \"dataset\", \"updated\",\"time_zone\"], axis=1)\n",
    "data[\"fake\"]  = data[\"fake\"].drop([\"id\", \"name\", \"screen_name\", \"statuses_count\", \"created_at\", \"lang\", \"location\", \"geo_enabled\", \"default_profile_image\", \"profile_image_url\", \"profile_banner_url\", \"profile_use_background_image\", \"profile_background_image_url_https\", \"profile_text_color\", \"profile_image_url_https\", \"profile_sidebar_border_color\", \"profile_background_tile\", \"profile_sidebar_fill_color\", \"profile_background_image_url\", \"profile_background_color\", \"profile_link_color\", \"utc_offset\", \"protected\", \"verified\", \"dataset\", \"updated\", \"time_zone\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05a0022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_default_profile(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if l == 1.:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_description(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if type(l) == str:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_url(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if type(l) == str and len(l) > 0:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_timezone(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if type(l) == str and len(l) > 0:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def is_listed(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if l > 0.:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_favourites(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if l > 0.:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def friends_followers_ratio(friends, followers):\n",
    "    ret = []\n",
    "    for fr, fo in zip(friends, followers):\n",
    "        if isnan(fo) or fo == 0.:\n",
    "            ret.append(-1.)\n",
    "        else:\n",
    "            ret.append(fr/fo)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c91631e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"][\"fr_fo\"] = friends_followers_ratio(data[\"legit\"][\"friends_count\"], data[\"legit\"][\"followers_count\"])\n",
    "data[\"legit\"][\"has_fav\"] = has_favourites(data[\"legit\"][\"favourites_count\"])\n",
    "data[\"legit\"][\"is_listed\"] = is_listed(data[\"legit\"][\"listed_count\"])\n",
    "data[\"legit\"][\"url\"] = has_url(data[\"legit\"][\"url\"])\n",
    "data[\"legit\"][\"default_profile\"] = is_default_profile(data[\"legit\"][\"default_profile\"])\n",
    "data[\"legit\"][\"description\"] = has_description(data[\"legit\"][\"description\"])\n",
    "\n",
    "data[\"fake\"][\"fr_fo\"] = friends_followers_ratio(data[\"fake\"][\"friends_count\"], data[\"fake\"][\"followers_count\"])\n",
    "data[\"fake\"][\"has_fav\"] = has_favourites(data[\"fake\"][\"favourites_count\"])\n",
    "data[\"fake\"][\"is_listed\"] = is_listed(data[\"fake\"][\"listed_count\"])\n",
    "data[\"fake\"][\"url\"] = has_url(data[\"fake\"][\"url\"])\n",
    "data[\"fake\"][\"default_profile\"] = is_default_profile(data[\"fake\"][\"default_profile\"])\n",
    "data[\"fake\"][\"description\"] = has_description(data[\"fake\"][\"description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "179b183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"].drop([\"followers_count\", \"friends_count\", \"favourites_count\", \"listed_count\"],axis=1, inplace=True)\n",
    "data[\"fake\"].drop([\"followers_count\", \"friends_count\", \"favourites_count\", \"listed_count\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fe1b3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Available Columns  6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['url', 'default_profile', 'description', 'fr_fo', 'has_fav',\n",
       "       'is_listed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Final Available Columns \", len(data[\"legit\"].columns))\n",
    "data[\"legit\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7af47332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of legit accounts : 1481\n",
      "number of fake accounts  : 1337\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of legit accounts : {len(data['legit'])}\")\n",
    "print(f\"number of fake accounts  : {len(data['fake'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a47af7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"] = data[\"legit\"].values\n",
    "data[\"fake\"] = data[\"fake\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "539da12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"] = data[\"legit\"].astype(np.float64)\n",
    "data[\"fake\"] = data[\"fake\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3347db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_legit = len(data[\"legit\"])\n",
    "n_fake = len(data[\"fake\"])\n",
    "\n",
    "train_legit = data[\"legit\"][:int(n_legit*.8)]\n",
    "train_fake = data[\"fake\"][:int(n_fake*.8)]\n",
    "\n",
    "test_legit = data[\"legit\"][int(n_legit*.8):]\n",
    "test_fake = data[\"fake\"][int(n_fake*.8):]\n",
    "\n",
    "valid_legit = train_legit[int(len(train_legit)*.8):]\n",
    "valid_fake = train_fake[int(len(train_fake)*.8):]\n",
    "train_legit = train_legit[:int(len(train_legit)*.8)]\n",
    "train_fake = train_fake[:int(len(train_fake)*.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9055b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_class_weights(labels):\n",
    "    n_classes = len(labels[0])\n",
    "    class_counts = [0 for _ in range(int(n_classes))]\n",
    "    for label in labels:\n",
    "        class_counts[label.index(1)] += 1\n",
    "    return {i : (1. / class_counts[i]) * float(len(labels)) / float(n_classes) for i in range(int(n_classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03e11b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "class_counts = [0,0]\n",
    "\n",
    "# legit -> [1.,0.]\n",
    "# fake -> [0.,1.]\n",
    "\n",
    "for legit in train_legit:\n",
    "    x_train.append(legit)\n",
    "    y_train.append([1.,0.])\n",
    "    class_counts[0] += 1\n",
    "    \n",
    "for fake in train_fake:\n",
    "    x_train.append(fake)\n",
    "    y_train.append([0.,1.])\n",
    "    class_counts[1] += 1\n",
    "    \n",
    "for legit in valid_legit:\n",
    "    x_valid.append(legit)\n",
    "    y_valid.append([1.,0.])\n",
    "    \n",
    "for fake in valid_fake:\n",
    "    x_valid.append(fake)\n",
    "    y_valid.append([0.,1.])\n",
    "\n",
    "for legit in test_legit:\n",
    "    x_test.append(legit)\n",
    "    y_test.append([1.,0.])\n",
    "    \n",
    "for fake in test_fake:\n",
    "    x_test.append(fake)\n",
    "    y_test.append([0.,1.])\n",
    "\n",
    "class_weights = get_class_weights(y_train)\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_valid = np.array(x_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cefed58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9514255543822597, 1: 1.0538011695906433}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b8cf725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "54cc26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 16)                112       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 362\n",
      "Trainable params: 314\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = tf.keras.Input((6))\n",
    "y = tf.keras.layers.Dense(16, activation=\"relu\", kernel_regularizer=\"l2\")(x)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dense(8, activation=\"relu\", kernel_regularizer=\"l2\")(y)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dense(2, activation=\"softmax\", kernel_regularizer=\"l2\")(y)\n",
    "model = tf.keras.models.Model(x, y)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70e7cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduceLR_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "          monitor='val_loss', factor=0.5, patience=10,\n",
    "          min_delta=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8cd0cd23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s 49ms/step - loss: 0.9317 - acc: 0.5339 - val_loss: 1.3279 - val_acc: 0.4834\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8558 - acc: 0.6204 - val_loss: 1.1883 - val_acc: 0.4678\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7754 - acc: 0.7303 - val_loss: 1.0893 - val_acc: 0.4235\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7206 - acc: 0.8074 - val_loss: 1.0101 - val_acc: 0.3769\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6678 - acc: 0.8485 - val_loss: 0.9415 - val_acc: 0.4324\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6235 - acc: 0.8812 - val_loss: 0.8713 - val_acc: 0.5388\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5711 - acc: 0.9107 - val_loss: 0.8094 - val_acc: 0.7251\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5323 - acc: 0.9329 - val_loss: 0.7547 - val_acc: 0.8559\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4980 - acc: 0.9467 - val_loss: 0.7059 - val_acc: 0.9202\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4745 - acc: 0.9506 - val_loss: 0.6655 - val_acc: 0.9557\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4504 - acc: 0.9545 - val_loss: 0.6313 - val_acc: 0.9690\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4310 - acc: 0.9562 - val_loss: 0.5987 - val_acc: 0.9756\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4134 - acc: 0.9623 - val_loss: 0.5700 - val_acc: 0.9756\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3959 - acc: 0.9645 - val_loss: 0.5443 - val_acc: 0.9756\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3808 - acc: 0.9667 - val_loss: 0.5198 - val_acc: 0.9823\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3639 - acc: 0.9689 - val_loss: 0.4973 - val_acc: 0.9823\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3492 - acc: 0.9723 - val_loss: 0.4761 - val_acc: 0.9823\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3362 - acc: 0.9761 - val_loss: 0.4558 - val_acc: 0.9823\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3232 - acc: 0.9784 - val_loss: 0.4366 - val_acc: 0.9823\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3093 - acc: 0.9800 - val_loss: 0.4204 - val_acc: 0.9845\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2982 - acc: 0.9817 - val_loss: 0.4065 - val_acc: 0.9845\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2869 - acc: 0.9822 - val_loss: 0.3931 - val_acc: 0.9845\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2789 - acc: 0.9834 - val_loss: 0.3807 - val_acc: 0.9845\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2676 - acc: 0.9850 - val_loss: 0.3715 - val_acc: 0.9845\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2603 - acc: 0.9856 - val_loss: 0.3633 - val_acc: 0.9889\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2519 - acc: 0.9856 - val_loss: 0.3553 - val_acc: 0.9889\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2457 - acc: 0.9867 - val_loss: 0.3491 - val_acc: 0.9889\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2370 - acc: 0.9883 - val_loss: 0.3451 - val_acc: 0.9911\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2296 - acc: 0.9900 - val_loss: 0.3381 - val_acc: 0.9911\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2259 - acc: 0.9889 - val_loss: 0.3313 - val_acc: 0.9933\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.2187 - acc: 0.9900 - val_loss: 0.3220 - val_acc: 0.9933\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.2124 - acc: 0.9900 - val_loss: 0.3149 - val_acc: 0.9933\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2092 - acc: 0.9911 - val_loss: 0.3116 - val_acc: 0.9933\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2000 - acc: 0.9906 - val_loss: 0.3090 - val_acc: 0.9933\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1956 - acc: 0.9917 - val_loss: 0.3004 - val_acc: 0.9933\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1911 - acc: 0.9928 - val_loss: 0.2948 - val_acc: 0.9933\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1860 - acc: 0.9922 - val_loss: 0.2942 - val_acc: 0.9933\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1817 - acc: 0.9917 - val_loss: 0.3016 - val_acc: 0.9911\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1777 - acc: 0.9928 - val_loss: 0.2992 - val_acc: 0.9911\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1729 - acc: 0.9928 - val_loss: 0.2953 - val_acc: 0.9911\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1680 - acc: 0.9939 - val_loss: 0.2974 - val_acc: 0.9911\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1662 - acc: 0.9933 - val_loss: 0.3009 - val_acc: 0.9889\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1610 - acc: 0.9945 - val_loss: 0.2914 - val_acc: 0.9889\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1580 - acc: 0.9950 - val_loss: 0.2871 - val_acc: 0.9911\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1546 - acc: 0.9945 - val_loss: 0.2778 - val_acc: 0.9911\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1530 - acc: 0.9939 - val_loss: 0.2771 - val_acc: 0.9911\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1522 - acc: 0.9956 - val_loss: 0.2678 - val_acc: 0.9911\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1471 - acc: 0.9939 - val_loss: 0.2565 - val_acc: 0.9933\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1435 - acc: 0.9945 - val_loss: 0.2399 - val_acc: 0.9889\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1427 - acc: 0.9939 - val_loss: 0.2334 - val_acc: 0.9889\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1410 - acc: 0.9939 - val_loss: 0.2272 - val_acc: 0.9889\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1367 - acc: 0.9950 - val_loss: 0.2384 - val_acc: 0.9911\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1350 - acc: 0.9945 - val_loss: 0.2483 - val_acc: 0.9889\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1336 - acc: 0.9950 - val_loss: 0.2310 - val_acc: 0.9911\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1308 - acc: 0.9950 - val_loss: 0.2244 - val_acc: 0.9889\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1282 - acc: 0.9945 - val_loss: 0.2089 - val_acc: 0.9889\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1266 - acc: 0.9950 - val_loss: 0.2082 - val_acc: 0.9889\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1262 - acc: 0.9956 - val_loss: 0.2059 - val_acc: 0.9889\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1239 - acc: 0.9950 - val_loss: 0.2005 - val_acc: 0.9889\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1213 - acc: 0.9956 - val_loss: 0.1938 - val_acc: 0.9889\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1201 - acc: 0.9956 - val_loss: 0.1903 - val_acc: 0.9889\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1169 - acc: 0.9956 - val_loss: 0.1920 - val_acc: 0.9889\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1157 - acc: 0.9956 - val_loss: 0.1901 - val_acc: 0.9889\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1140 - acc: 0.9956 - val_loss: 0.1822 - val_acc: 0.9889\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1121 - acc: 0.9961 - val_loss: 0.1824 - val_acc: 0.9889\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1109 - acc: 0.9956 - val_loss: 0.1986 - val_acc: 0.9889\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1100 - acc: 0.9956 - val_loss: 0.1813 - val_acc: 0.9889\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1113 - acc: 0.9945 - val_loss: 0.1733 - val_acc: 0.9889\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1074 - acc: 0.9950 - val_loss: 0.1773 - val_acc: 0.9889\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1058 - acc: 0.9950 - val_loss: 0.1794 - val_acc: 0.9889\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1056 - acc: 0.9945 - val_loss: 0.1742 - val_acc: 0.9889\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1035 - acc: 0.9950 - val_loss: 0.1692 - val_acc: 0.9889\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1037 - acc: 0.9945 - val_loss: 0.1599 - val_acc: 0.9889\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1034 - acc: 0.9950 - val_loss: 0.1601 - val_acc: 0.9911\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1034 - acc: 0.9945 - val_loss: 0.1555 - val_acc: 0.9889\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1038 - acc: 0.9956 - val_loss: 0.1485 - val_acc: 0.9889\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0991 - acc: 0.9950 - val_loss: 0.1447 - val_acc: 0.9911\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0990 - acc: 0.9950 - val_loss: 0.1431 - val_acc: 0.9911\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0970 - acc: 0.9956 - val_loss: 0.1447 - val_acc: 0.9911\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0953 - acc: 0.9961 - val_loss: 0.1429 - val_acc: 0.9911\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0948 - acc: 0.9956 - val_loss: 0.1390 - val_acc: 0.9911\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0957 - acc: 0.9961 - val_loss: 0.1337 - val_acc: 0.9911\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0929 - acc: 0.9950 - val_loss: 0.1318 - val_acc: 0.9889\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0929 - acc: 0.9950 - val_loss: 0.1302 - val_acc: 0.9889\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0914 - acc: 0.9956 - val_loss: 0.1284 - val_acc: 0.9911\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0900 - acc: 0.9961 - val_loss: 0.1285 - val_acc: 0.9911\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0889 - acc: 0.9956 - val_loss: 0.1281 - val_acc: 0.9911\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0903 - acc: 0.9961 - val_loss: 0.1256 - val_acc: 0.9911\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0877 - acc: 0.9961 - val_loss: 0.1241 - val_acc: 0.9911\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0880 - acc: 0.9950 - val_loss: 0.1241 - val_acc: 0.9911\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0866 - acc: 0.9956 - val_loss: 0.1271 - val_acc: 0.9911\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0857 - acc: 0.9956 - val_loss: 0.1254 - val_acc: 0.9911\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0852 - acc: 0.9967 - val_loss: 0.1237 - val_acc: 0.9911\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0864 - acc: 0.9950 - val_loss: 0.1216 - val_acc: 0.9933\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0846 - acc: 0.9956 - val_loss: 0.1177 - val_acc: 0.9933\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0830 - acc: 0.9956 - val_loss: 0.1163 - val_acc: 0.9933\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0816 - acc: 0.9961 - val_loss: 0.1132 - val_acc: 0.9911\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0805 - acc: 0.9967 - val_loss: 0.1115 - val_acc: 0.9933\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0805 - acc: 0.9961 - val_loss: 0.1099 - val_acc: 0.9933\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0806 - acc: 0.9967 - val_loss: 0.1091 - val_acc: 0.9933\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0796 - acc: 0.9961 - val_loss: 0.1089 - val_acc: 0.9911\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0788 - acc: 0.9961 - val_loss: 0.1090 - val_acc: 0.9911\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0788 - acc: 0.9961 - val_loss: 0.1103 - val_acc: 0.9933\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0773 - acc: 0.9956 - val_loss: 0.1086 - val_acc: 0.9933\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0763 - acc: 0.9961 - val_loss: 0.1083 - val_acc: 0.9933\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0761 - acc: 0.9961 - val_loss: 0.1187 - val_acc: 0.9911\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0775 - acc: 0.9950 - val_loss: 0.1161 - val_acc: 0.9911\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0782 - acc: 0.9950 - val_loss: 0.1294 - val_acc: 0.9889\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0789 - acc: 0.9933 - val_loss: 0.1304 - val_acc: 0.9845\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0776 - acc: 0.9945 - val_loss: 0.1199 - val_acc: 0.9867\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0761 - acc: 0.9939 - val_loss: 0.1101 - val_acc: 0.9911\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0745 - acc: 0.9939 - val_loss: 0.1038 - val_acc: 0.9911\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0750 - acc: 0.9950 - val_loss: 0.1015 - val_acc: 0.9911\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0742 - acc: 0.9950 - val_loss: 0.0999 - val_acc: 0.9933\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0729 - acc: 0.9961 - val_loss: 0.1045 - val_acc: 0.9911\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0739 - acc: 0.9961 - val_loss: 0.1044 - val_acc: 0.9911\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0717 - acc: 0.9967 - val_loss: 0.1033 - val_acc: 0.9911\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0701 - acc: 0.9961 - val_loss: 0.0975 - val_acc: 0.9933\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0705 - acc: 0.9950 - val_loss: 0.0952 - val_acc: 0.9911\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0713 - acc: 0.9945 - val_loss: 0.1014 - val_acc: 0.9889\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0726 - acc: 0.9922 - val_loss: 0.0975 - val_acc: 0.9889\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0708 - acc: 0.9939 - val_loss: 0.0929 - val_acc: 0.9911\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0688 - acc: 0.9945 - val_loss: 0.0919 - val_acc: 0.9911\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0672 - acc: 0.9956 - val_loss: 0.0898 - val_acc: 0.9911\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0684 - acc: 0.9956 - val_loss: 0.0906 - val_acc: 0.9911\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0668 - acc: 0.9956 - val_loss: 0.0904 - val_acc: 0.9911\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0653 - acc: 0.9961 - val_loss: 0.0901 - val_acc: 0.9911\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0658 - acc: 0.9956 - val_loss: 0.0901 - val_acc: 0.9911\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0723 - acc: 0.9928 - val_loss: 0.0901 - val_acc: 0.9911\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0666 - acc: 0.9956 - val_loss: 0.0910 - val_acc: 0.9911\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0687 - acc: 0.9956 - val_loss: 0.0886 - val_acc: 0.9911\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0707 - acc: 0.9956 - val_loss: 0.0856 - val_acc: 0.9911\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0671 - acc: 0.9961 - val_loss: 0.0844 - val_acc: 0.9911\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0659 - acc: 0.9961 - val_loss: 0.0847 - val_acc: 0.9911\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0659 - acc: 0.9945 - val_loss: 0.0842 - val_acc: 0.9911\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0657 - acc: 0.9961 - val_loss: 0.0829 - val_acc: 0.9911\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0644 - acc: 0.9961 - val_loss: 0.0823 - val_acc: 0.9911\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0635 - acc: 0.9956 - val_loss: 0.0841 - val_acc: 0.9911\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0628 - acc: 0.9961 - val_loss: 0.0814 - val_acc: 0.9933\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0628 - acc: 0.9956 - val_loss: 0.0789 - val_acc: 0.9911\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0618 - acc: 0.9961 - val_loss: 0.0800 - val_acc: 0.9911\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0639 - acc: 0.9950 - val_loss: 0.0845 - val_acc: 0.9933\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0664 - acc: 0.9945 - val_loss: 0.0841 - val_acc: 0.9911\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0628 - acc: 0.9956 - val_loss: 0.0908 - val_acc: 0.9889\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0666 - acc: 0.9945 - val_loss: 0.0950 - val_acc: 0.9867\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0679 - acc: 0.9939 - val_loss: 0.0907 - val_acc: 0.9889\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0645 - acc: 0.9956 - val_loss: 0.0830 - val_acc: 0.9889\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0655 - acc: 0.9933 - val_loss: 0.0817 - val_acc: 0.9889\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0611 - acc: 0.9961 - val_loss: 0.0868 - val_acc: 0.9889\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0623 - acc: 0.9950 - val_loss: 0.0901 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0612 - acc: 0.9956 - val_loss: 0.0842 - val_acc: 0.9889\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0614 - acc: 0.9950 - val_loss: 0.0790 - val_acc: 0.9889\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0617 - acc: 0.9950 - val_loss: 0.0807 - val_acc: 0.9867\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0597 - acc: 0.9956 - val_loss: 0.0832 - val_acc: 0.9867\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0621 - acc: 0.9950 - val_loss: 0.0836 - val_acc: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1adb6bfdc10>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=200, validation_data=(x_valid, y_valid), shuffle=True, batch_size=256, callbacks=[early_stopping,reduceLR_cb], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6acd9472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0833 - acc: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08326158672571182, 0.991150438785553]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "32775f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8c95d403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[294,   3],\n",
       "       [  2, 266]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(np.argmax(y_test,-1), np.argmax(preds,-1))\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1dfeb970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, title='CONFUSION MATRIX', cmap=plt.cm.Reds):\n",
    "    target_names=['Legit','Fake']\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "75c630cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c88dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/classifier_1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
