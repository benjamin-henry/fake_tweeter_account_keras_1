{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20e9fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2515ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data[\"fake\"]  = pd.read_csv(\"DATASET/fusers.csv\")\n",
    "data[\"legit\"] = pd.read_csv(\"DATASET/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e992e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"] = data[\"legit\"].drop([\"id\", \"name\", \"screen_name\", \"statuses_count\", \"created_at\", \"lang\", \"location\", \"geo_enabled\", \"default_profile_image\", \"profile_image_url\", \"profile_banner_url\", \"profile_use_background_image\", \"profile_background_image_url_https\", \"profile_text_color\", \"profile_image_url_https\", \"profile_sidebar_border_color\", \"profile_background_tile\", \"profile_sidebar_fill_color\", \"profile_background_image_url\", \"profile_background_color\", \"profile_link_color\", \"utc_offset\", \"protected\", \"verified\", \"dataset\", \"updated\"], axis=1)\n",
    "data[\"fake\"]  = data[\"fake\"].drop([\"id\", \"name\", \"screen_name\", \"statuses_count\", \"created_at\", \"lang\", \"location\", \"geo_enabled\", \"default_profile_image\", \"profile_image_url\", \"profile_banner_url\", \"profile_use_background_image\", \"profile_background_image_url_https\", \"profile_text_color\", \"profile_image_url_https\", \"profile_sidebar_border_color\", \"profile_background_tile\", \"profile_sidebar_fill_color\", \"profile_background_image_url\", \"profile_background_color\", \"profile_link_color\", \"utc_offset\", \"protected\", \"verified\", \"dataset\", \"updated\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05a0022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_default_profile(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if l == 1.:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_description(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if type(l) == str:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_url(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if type(l) == str and len(l) > 0:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_timezone(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if type(l) == str and len(l) > 0:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def is_listed(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if l > 0.:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_favourites(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if l > 0.:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def friends_followers_ratio(friends, followers):\n",
    "    ret = []\n",
    "    for fr, fo in zip(friends, followers):\n",
    "        if isnan(fo) or fo == 0.:\n",
    "            ret.append(-1.)\n",
    "        else:\n",
    "            ret.append(fr/fo)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c91631e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"][\"fr_fo\"] = friends_followers_ratio(data[\"legit\"][\"friends_count\"], data[\"legit\"][\"followers_count\"])\n",
    "data[\"legit\"][\"has_fav\"] = has_favourites(data[\"legit\"][\"favourites_count\"])\n",
    "data[\"legit\"][\"is_listed\"] = is_listed(data[\"legit\"][\"listed_count\"])\n",
    "data[\"legit\"][\"url\"] = has_url(data[\"legit\"][\"url\"])\n",
    "data[\"legit\"][\"time_zone\"] = has_timezone(data[\"legit\"][\"time_zone\"])\n",
    "data[\"legit\"][\"default_profile\"] = is_default_profile(data[\"legit\"][\"default_profile\"])\n",
    "data[\"legit\"][\"description\"] = has_description(data[\"legit\"][\"description\"])\n",
    "\n",
    "data[\"fake\"][\"fr_fo\"] = friends_followers_ratio(data[\"fake\"][\"friends_count\"], data[\"fake\"][\"followers_count\"])\n",
    "data[\"fake\"][\"has_fav\"] = has_favourites(data[\"fake\"][\"favourites_count\"])\n",
    "data[\"fake\"][\"is_listed\"] = is_listed(data[\"fake\"][\"listed_count\"])\n",
    "data[\"fake\"][\"url\"] = has_url(data[\"fake\"][\"url\"])\n",
    "data[\"fake\"][\"time_zone\"] = has_timezone(data[\"fake\"][\"time_zone\"])\n",
    "data[\"fake\"][\"default_profile\"] = is_default_profile(data[\"fake\"][\"default_profile\"])\n",
    "data[\"fake\"][\"description\"] = has_description(data[\"fake\"][\"description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "179b183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"].drop([\"followers_count\", \"friends_count\", \"favourites_count\", \"listed_count\"],axis=1, inplace=True)\n",
    "data[\"fake\"].drop([\"followers_count\", \"friends_count\", \"favourites_count\", \"listed_count\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fe1b3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Available Columns  7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['url', 'time_zone', 'default_profile', 'description', 'fr_fo',\n",
       "       'has_fav', 'is_listed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Final Available Columns \", len(data[\"legit\"].columns))\n",
    "data[\"legit\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7af47332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of legit accounts : 1481\n",
      "number of fake accounts  : 1337\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of legit accounts : {len(data['legit'])}\")\n",
    "print(f\"number of fake accounts  : {len(data['fake'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a47af7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"] = data[\"legit\"].values\n",
    "data[\"fake\"] = data[\"fake\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "539da12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"] = data[\"legit\"].astype(np.float64)\n",
    "data[\"fake\"] = data[\"fake\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3347db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_legit = len(data[\"legit\"])\n",
    "n_fake = len(data[\"fake\"])\n",
    "\n",
    "train_legit = data[\"legit\"][:int(n_legit*.8)]\n",
    "train_fake = data[\"fake\"][:int(n_fake*.8)]\n",
    "\n",
    "test_legit = data[\"legit\"][int(n_legit*.8):]\n",
    "test_fake = data[\"fake\"][int(n_fake*.8):]\n",
    "\n",
    "valid_legit = train_legit[int(len(train_legit)*.8):]\n",
    "valid_fake = train_fake[int(len(train_fake)*.8):]\n",
    "train_legit = train_legit[:int(len(train_legit)*.8)]\n",
    "train_fake = train_fake[:int(len(train_fake)*.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9055b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_class_weights(labels):\n",
    "    n_classes = len(labels[0])\n",
    "    class_counts = [0 for _ in range(int(n_classes))]\n",
    "    for label in labels:\n",
    "        class_counts[label.index(1)] += 1\n",
    "    return {i : (1. / class_counts[i]) * float(len(labels)) / float(n_classes) for i in range(int(n_classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03e11b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "class_counts = [0,0]\n",
    "\n",
    "# legit -> [1.,0.]\n",
    "# fake -> [0.,1.]\n",
    "\n",
    "for legit in train_legit:\n",
    "    x_train.append(legit)\n",
    "    y_train.append([1.,0.])\n",
    "    class_counts[0] += 1\n",
    "    \n",
    "for fake in train_fake:\n",
    "    x_train.append(fake)\n",
    "    y_train.append([0.,1.])\n",
    "    class_counts[1] += 1\n",
    "    \n",
    "for legit in valid_legit:\n",
    "    x_valid.append(legit)\n",
    "    y_valid.append([1.,0.])\n",
    "    \n",
    "for fake in valid_fake:\n",
    "    x_valid.append(fake)\n",
    "    y_valid.append([0.,1.])\n",
    "\n",
    "for legit in test_legit:\n",
    "    x_test.append(legit)\n",
    "    y_test.append([1.,0.])\n",
    "    \n",
    "for fake in test_fake:\n",
    "    x_test.append(fake)\n",
    "    y_test.append([0.,1.])\n",
    "\n",
    "class_weights = get_class_weights(y_train)\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_valid = np.array(x_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cefed58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9514255543822597, 1: 1.0538011695906433}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b8cf725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54cc26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 378\n",
      "Trainable params: 330\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = tf.keras.Input((7))\n",
    "y = tf.keras.layers.Dense(16, activation=\"relu\", kernel_regularizer=\"l2\")(x)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dense(8, activation=\"relu\", kernel_regularizer=\"l2\")(y)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dense(2, activation=\"softmax\", kernel_regularizer=\"l2\")(y)\n",
    "model = tf.keras.models.Model(x, y)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "70e7cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduceLR_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "          monitor='val_loss', factor=0.5, patience=10,\n",
    "          min_delta=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8cd0cd23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 1s 31ms/step - loss: 0.5387 - acc: 0.9018 - val_loss: 0.7192 - val_acc: 0.7228\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.3824 - acc: 0.9778 - val_loss: 0.6348 - val_acc: 0.8670\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.3503 - acc: 0.9850 - val_loss: 0.5682 - val_acc: 0.9091\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.3253 - acc: 0.9850 - val_loss: 0.5086 - val_acc: 0.9512\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.3129 - acc: 0.9872 - val_loss: 0.4642 - val_acc: 0.9712\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2915 - acc: 0.9867 - val_loss: 0.4307 - val_acc: 0.9756\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2805 - acc: 0.9872 - val_loss: 0.4055 - val_acc: 0.9845\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2665 - acc: 0.9878 - val_loss: 0.3844 - val_acc: 0.9845\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.2559 - acc: 0.9900 - val_loss: 0.3682 - val_acc: 0.9823\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2470 - acc: 0.9900 - val_loss: 0.3553 - val_acc: 0.9756\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.2373 - acc: 0.9889 - val_loss: 0.3456 - val_acc: 0.9778\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2312 - acc: 0.9883 - val_loss: 0.3421 - val_acc: 0.9756\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.2223 - acc: 0.9883 - val_loss: 0.3366 - val_acc: 0.9778\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2126 - acc: 0.9911 - val_loss: 0.3284 - val_acc: 0.9778\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.2054 - acc: 0.9917 - val_loss: 0.3238 - val_acc: 0.9778\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1997 - acc: 0.9922 - val_loss: 0.3189 - val_acc: 0.9734\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1938 - acc: 0.9911 - val_loss: 0.3042 - val_acc: 0.9778\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1898 - acc: 0.9895 - val_loss: 0.3028 - val_acc: 0.9778\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1815 - acc: 0.9906 - val_loss: 0.3002 - val_acc: 0.9800\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1772 - acc: 0.9928 - val_loss: 0.2964 - val_acc: 0.9800\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1715 - acc: 0.9917 - val_loss: 0.2948 - val_acc: 0.9778\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1663 - acc: 0.9917 - val_loss: 0.2859 - val_acc: 0.9778\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1601 - acc: 0.9922 - val_loss: 0.2825 - val_acc: 0.9756\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1570 - acc: 0.9939 - val_loss: 0.2809 - val_acc: 0.9756\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1518 - acc: 0.9917 - val_loss: 0.2751 - val_acc: 0.9778\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1472 - acc: 0.9933 - val_loss: 0.2673 - val_acc: 0.9800\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1449 - acc: 0.9928 - val_loss: 0.2661 - val_acc: 0.9823\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1407 - acc: 0.9922 - val_loss: 0.2676 - val_acc: 0.9823\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1351 - acc: 0.9945 - val_loss: 0.2588 - val_acc: 0.9823\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1312 - acc: 0.9945 - val_loss: 0.2527 - val_acc: 0.9823\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1290 - acc: 0.9945 - val_loss: 0.2559 - val_acc: 0.9823\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1240 - acc: 0.9945 - val_loss: 0.2609 - val_acc: 0.9823\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1221 - acc: 0.9950 - val_loss: 0.2720 - val_acc: 0.9823\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1188 - acc: 0.9939 - val_loss: 0.2676 - val_acc: 0.9845\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1163 - acc: 0.9956 - val_loss: 0.2620 - val_acc: 0.9845\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1190 - acc: 0.9922 - val_loss: 0.2669 - val_acc: 0.9867\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1108 - acc: 0.9950 - val_loss: 0.4194 - val_acc: 0.7406\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1092 - acc: 0.9950 - val_loss: 0.3402 - val_acc: 0.9933\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1114 - acc: 0.9933 - val_loss: 0.3127 - val_acc: 0.9956\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1054 - acc: 0.9945 - val_loss: 0.4801 - val_acc: 0.6984\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1046 - acc: 0.9950 - val_loss: 0.4289 - val_acc: 0.7206\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1036 - acc: 0.9950 - val_loss: 0.3504 - val_acc: 0.9135\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1029 - acc: 0.9950 - val_loss: 0.2964 - val_acc: 0.9933\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1024 - acc: 0.9956 - val_loss: 0.2663 - val_acc: 0.9933\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1002 - acc: 0.9950 - val_loss: 0.2206 - val_acc: 0.9956\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0972 - acc: 0.9961 - val_loss: 0.1925 - val_acc: 0.9956\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0967 - acc: 0.9956 - val_loss: 0.1713 - val_acc: 0.9956\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0965 - acc: 0.9945 - val_loss: 0.1521 - val_acc: 0.9956\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0936 - acc: 0.9961 - val_loss: 0.1422 - val_acc: 0.9933\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0944 - acc: 0.9950 - val_loss: 0.1368 - val_acc: 0.9911\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0932 - acc: 0.9939 - val_loss: 0.1323 - val_acc: 0.9911\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0909 - acc: 0.9961 - val_loss: 0.1300 - val_acc: 0.9911\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0903 - acc: 0.9961 - val_loss: 0.1277 - val_acc: 0.9911\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0903 - acc: 0.9950 - val_loss: 0.1238 - val_acc: 0.9911\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0884 - acc: 0.9950 - val_loss: 0.1184 - val_acc: 0.9933\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0892 - acc: 0.9950 - val_loss: 0.1174 - val_acc: 0.9911\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0873 - acc: 0.9950 - val_loss: 0.1178 - val_acc: 0.9911\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0878 - acc: 0.9945 - val_loss: 0.1228 - val_acc: 0.9911\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0847 - acc: 0.9967 - val_loss: 0.1650 - val_acc: 0.9933\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0831 - acc: 0.9956 - val_loss: 0.1566 - val_acc: 0.9933\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0844 - acc: 0.9967 - val_loss: 0.1356 - val_acc: 0.9933\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0812 - acc: 0.9967 - val_loss: 0.1214 - val_acc: 0.9933\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0809 - acc: 0.9961 - val_loss: 0.1144 - val_acc: 0.9956\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0797 - acc: 0.9967 - val_loss: 0.1080 - val_acc: 0.9956\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0794 - acc: 0.9950 - val_loss: 0.1032 - val_acc: 0.9933\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0793 - acc: 0.9945 - val_loss: 0.1046 - val_acc: 0.9956\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0776 - acc: 0.9961 - val_loss: 0.1007 - val_acc: 0.9933\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0789 - acc: 0.9956 - val_loss: 0.0987 - val_acc: 0.9933\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0768 - acc: 0.9956 - val_loss: 0.0994 - val_acc: 0.9933\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0758 - acc: 0.9961 - val_loss: 0.0918 - val_acc: 0.9911\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0751 - acc: 0.9950 - val_loss: 0.0896 - val_acc: 0.9933\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0759 - acc: 0.9950 - val_loss: 0.0877 - val_acc: 0.9933\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0721 - acc: 0.9961 - val_loss: 0.0867 - val_acc: 0.9933\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0726 - acc: 0.9950 - val_loss: 0.0875 - val_acc: 0.9911\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0710 - acc: 0.9961 - val_loss: 0.0882 - val_acc: 0.9911\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0702 - acc: 0.9956 - val_loss: 0.0869 - val_acc: 0.9911\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0709 - acc: 0.9961 - val_loss: 0.0861 - val_acc: 0.9911\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0698 - acc: 0.9961 - val_loss: 0.0823 - val_acc: 0.9933\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0702 - acc: 0.9956 - val_loss: 0.0821 - val_acc: 0.9933\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0680 - acc: 0.9967 - val_loss: 0.0845 - val_acc: 0.9933\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0676 - acc: 0.9950 - val_loss: 0.0847 - val_acc: 0.9956\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0670 - acc: 0.9961 - val_loss: 0.0838 - val_acc: 0.9956\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0665 - acc: 0.9961 - val_loss: 0.0754 - val_acc: 0.9911\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0693 - acc: 0.9956 - val_loss: 0.0758 - val_acc: 0.9911\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0671 - acc: 0.9956 - val_loss: 0.0748 - val_acc: 0.9911\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0646 - acc: 0.9956 - val_loss: 0.0748 - val_acc: 0.9933\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0637 - acc: 0.9961 - val_loss: 0.0739 - val_acc: 0.9933\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0634 - acc: 0.9967 - val_loss: 0.0741 - val_acc: 0.9933\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0634 - acc: 0.9950 - val_loss: 0.0737 - val_acc: 0.9933\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0618 - acc: 0.9972 - val_loss: 0.0749 - val_acc: 0.9933\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0610 - acc: 0.9967 - val_loss: 0.0750 - val_acc: 0.9933\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0645 - acc: 0.9956 - val_loss: 0.0769 - val_acc: 0.9933\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0637 - acc: 0.9956 - val_loss: 0.1075 - val_acc: 0.9911\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0645 - acc: 0.9956 - val_loss: 0.0961 - val_acc: 0.9889\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0612 - acc: 0.9967 - val_loss: 0.0885 - val_acc: 0.9911\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0602 - acc: 0.9961 - val_loss: 0.0862 - val_acc: 0.9911\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0598 - acc: 0.9967 - val_loss: 0.0853 - val_acc: 0.9911\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0588 - acc: 0.9956 - val_loss: 0.0853 - val_acc: 0.9911\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0584 - acc: 0.9972 - val_loss: 0.0835 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0592 - acc: 0.9961 - val_loss: 0.0823 - val_acc: 0.9911\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0580 - acc: 0.9961 - val_loss: 0.0818 - val_acc: 0.9911\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0593 - acc: 0.9972 - val_loss: 0.0811 - val_acc: 0.9911\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0584 - acc: 0.9956 - val_loss: 0.0785 - val_acc: 0.9911\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0594 - acc: 0.9961 - val_loss: 0.0777 - val_acc: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f0d00bdc0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=200, validation_data=(x_valid, y_valid), shuffle=True, batch_size=128, callbacks=[early_stopping,reduceLR_cb], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6acd9472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0717 - acc: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07171624898910522, 0.9929203391075134]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32775f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c95d403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[295,   2],\n",
       "       [  2, 266]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(np.argmax(y_test,-1), np.argmax(preds,-1))\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1dfeb970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, title='CONFUSION MATRIX', cmap=plt.cm.Reds):\n",
    "    target_names=['Legit','Fake']\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75c630cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c88dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/classifier_1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
