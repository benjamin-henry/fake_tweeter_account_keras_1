{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f9ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb407de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data[\"fake\"]  = pd.read_csv(\"DATASET/fusers.csv\")\n",
    "data[\"legit\"] = pd.read_csv(\"DATASET/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd7d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"] = data[\"legit\"].drop([\"id\", \"name\", \"screen_name\", \"statuses_count\", \"created_at\", \"lang\", \"location\", \"geo_enabled\", \"default_profile_image\", \"profile_image_url\", \"profile_banner_url\", \"profile_use_background_image\", \"profile_background_image_url_https\", \"profile_text_color\", \"profile_image_url_https\", \"profile_sidebar_border_color\", \"profile_background_tile\", \"profile_sidebar_fill_color\", \"profile_background_image_url\", \"profile_background_color\", \"profile_link_color\", \"utc_offset\", \"protected\", \"verified\", \"dataset\", \"updated\"], axis=1)\n",
    "data[\"fake\"]  = data[\"fake\"].drop([\"id\", \"name\", \"screen_name\", \"statuses_count\", \"created_at\", \"lang\", \"location\", \"geo_enabled\", \"default_profile_image\", \"profile_image_url\", \"profile_banner_url\", \"profile_use_background_image\", \"profile_background_image_url_https\", \"profile_text_color\", \"profile_image_url_https\", \"profile_sidebar_border_color\", \"profile_background_tile\", \"profile_sidebar_fill_color\", \"profile_background_image_url\", \"profile_background_color\", \"profile_link_color\", \"utc_offset\", \"protected\", \"verified\", \"dataset\", \"updated\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ab592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_default_profile(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if l == 1.:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_description(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if type(l) == str:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_url(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if type(l) == str and len(l) > 0:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_timezone(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if type(l) == str and len(l) > 0:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def is_listed(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if l > 0.:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def has_favourites(arr):\n",
    "    ret = []\n",
    "    for l in arr:\n",
    "        if l > 0.:\n",
    "            ret.append(1.)\n",
    "        else:\n",
    "            ret.append(-1.)\n",
    "    return ret\n",
    "\n",
    "def friends_followers_ratio(friends, followers):\n",
    "    ret = []\n",
    "    for fr, fo in zip(friends, followers):\n",
    "        if isnan(fo) or fo == 0.:\n",
    "            ret.append(-1.)\n",
    "        else:\n",
    "            ret.append(fr/fo)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d656451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"][\"fr_fo\"] = friends_followers_ratio(data[\"legit\"][\"friends_count\"], data[\"legit\"][\"followers_count\"])\n",
    "data[\"legit\"][\"has_fav\"] = has_favourites(data[\"legit\"][\"favourites_count\"])\n",
    "data[\"legit\"][\"is_listed\"] = is_listed(data[\"legit\"][\"listed_count\"])\n",
    "data[\"legit\"][\"url\"] = has_url(data[\"legit\"][\"url\"])\n",
    "data[\"legit\"][\"time_zone\"] = has_timezone(data[\"legit\"][\"time_zone\"])\n",
    "data[\"legit\"][\"default_profile\"] = is_default_profile(data[\"legit\"][\"default_profile\"])\n",
    "data[\"legit\"][\"description\"] = has_description(data[\"legit\"][\"description\"])\n",
    "\n",
    "data[\"fake\"][\"fr_fo\"] = friends_followers_ratio(data[\"fake\"][\"friends_count\"], data[\"fake\"][\"followers_count\"])\n",
    "data[\"fake\"][\"has_fav\"] = has_favourites(data[\"fake\"][\"favourites_count\"])\n",
    "data[\"fake\"][\"is_listed\"] = is_listed(data[\"fake\"][\"listed_count\"])\n",
    "data[\"fake\"][\"url\"] = has_url(data[\"fake\"][\"url\"])\n",
    "data[\"fake\"][\"time_zone\"] = has_timezone(data[\"fake\"][\"time_zone\"])\n",
    "data[\"fake\"][\"default_profile\"] = is_default_profile(data[\"fake\"][\"default_profile\"])\n",
    "data[\"fake\"][\"description\"] = has_description(data[\"fake\"][\"description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df0f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"].drop([\"followers_count\", \"friends_count\", \"favourites_count\", \"listed_count\"],axis=1, inplace=True)\n",
    "data[\"fake\"].drop([\"followers_count\", \"friends_count\", \"favourites_count\", \"listed_count\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b997903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Available Columns  7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['url', 'time_zone', 'default_profile', 'description', 'fr_fo',\n",
       "       'has_fav', 'is_listed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Final Available Columns \", len(data[\"legit\"].columns))\n",
    "data[\"legit\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ba2050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of legit accounts : 1481\n",
      "number of fake accounts  : 1337\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of legit accounts : {len(data['legit'])}\")\n",
    "print(f\"number of fake accounts  : {len(data['fake'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e78b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"] = data[\"legit\"].values\n",
    "data[\"fake\"] = data[\"fake\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054cdea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"legit\"] = data[\"legit\"].astype(np.float64)\n",
    "data[\"fake\"] = data[\"fake\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387b9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_class_weights(labels):\n",
    "    n_classes = len(labels[0])\n",
    "    class_counts = [0 for _ in range(int(n_classes))]\n",
    "    for label in labels:\n",
    "        class_counts[label.index(1)] += 1\n",
    "    return {i : (1. / class_counts[i]) * float(len(labels)) / float(n_classes) for i in range(int(n_classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f57b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "# legit -> [1.,0.]\n",
    "# fake -> [0.,1.]\n",
    "\n",
    "for row in data[\"legit\"]:\n",
    "    X.append(row)\n",
    "    Y.append([1.,0.])\n",
    "    \n",
    "for row in data[\"fake\"]:\n",
    "    X.append(row)\n",
    "    Y.append([0.,1.])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9348d2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9532502226179875, 1: 1.0515717092337917}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, \n",
    "    test_size=0.24, random_state=42)\n",
    "\n",
    "class_weights = get_class_weights(y_train.tolist())\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e80535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54a5bfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                128       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 378\n",
      "Trainable params: 330\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = tf.keras.Input((7))\n",
    "y = tf.keras.layers.Dense(16, activation=\"relu\", kernel_regularizer=\"l2\")(x)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dense(8, activation=\"relu\", kernel_regularizer=\"l2\")(y)\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dense(2, activation=\"softmax\", kernel_regularizer=\"l2\")(y)\n",
    "model = tf.keras.models.Model(x, y)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78d1a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduceLR_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "          monitor='val_loss', factor=0.5, patience=10,\n",
    "          min_delta=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd598cf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\benji\\documents\\python\\ml_env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 8s 139ms/step - loss: 0.5747 - acc: 0.9014 - val_loss: 0.6280 - val_acc: 0.8287\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4647 - acc: 0.9313 - val_loss: 0.5532 - val_acc: 0.9069\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.3900 - acc: 0.9491 - val_loss: 0.4954 - val_acc: 0.9439\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.3309 - acc: 0.9696 - val_loss: 0.4314 - val_acc: 0.9631\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.2892 - acc: 0.9846 - val_loss: 0.3795 - val_acc: 0.9690\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.2642 - acc: 0.9846 - val_loss: 0.3446 - val_acc: 0.9764\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2427 - acc: 0.9883 - val_loss: 0.3201 - val_acc: 0.9734\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.2281 - acc: 0.9888 - val_loss: 0.3034 - val_acc: 0.9719\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.2176 - acc: 0.9893 - val_loss: 0.2890 - val_acc: 0.9734\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2067 - acc: 0.9921 - val_loss: 0.2797 - val_acc: 0.9690\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1953 - acc: 0.9921 - val_loss: 0.2677 - val_acc: 0.9675\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1895 - acc: 0.9930 - val_loss: 0.2634 - val_acc: 0.9675\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1795 - acc: 0.9925 - val_loss: 0.2511 - val_acc: 0.9660\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1730 - acc: 0.9935 - val_loss: 0.2536 - val_acc: 0.9616\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1653 - acc: 0.9935 - val_loss: 0.2507 - val_acc: 0.9616\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.1604 - acc: 0.9921 - val_loss: 0.2498 - val_acc: 0.9601\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.1552 - acc: 0.9921 - val_loss: 0.2398 - val_acc: 0.9601\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.1476 - acc: 0.9944 - val_loss: 0.2292 - val_acc: 0.9616\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1441 - acc: 0.9930 - val_loss: 0.2306 - val_acc: 0.9616\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1383 - acc: 0.9939 - val_loss: 0.2288 - val_acc: 0.9808\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1320 - acc: 0.9944 - val_loss: 0.2234 - val_acc: 0.9838\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1288 - acc: 0.9944 - val_loss: 0.2009 - val_acc: 0.9882\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1231 - acc: 0.9925 - val_loss: 0.2279 - val_acc: 0.9808\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1198 - acc: 0.9944 - val_loss: 0.2287 - val_acc: 0.9778\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1150 - acc: 0.9935 - val_loss: 0.2229 - val_acc: 0.9823\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1118 - acc: 0.9935 - val_loss: 0.2127 - val_acc: 0.9808\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1087 - acc: 0.9944 - val_loss: 0.2174 - val_acc: 0.9838\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1061 - acc: 0.9944 - val_loss: 0.2043 - val_acc: 0.9808\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1001 - acc: 0.9949 - val_loss: 0.1786 - val_acc: 0.9852\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0982 - acc: 0.9949 - val_loss: 0.1739 - val_acc: 0.9867\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0953 - acc: 0.9939 - val_loss: 0.2049 - val_acc: 0.9793\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0942 - acc: 0.9949 - val_loss: 0.1313 - val_acc: 0.9956\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0903 - acc: 0.9953 - val_loss: 0.1580 - val_acc: 0.9882\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0900 - acc: 0.9935 - val_loss: 0.1323 - val_acc: 0.9941\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0890 - acc: 0.9935 - val_loss: 0.1559 - val_acc: 0.9838\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0852 - acc: 0.9939 - val_loss: 0.1148 - val_acc: 0.9956\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0802 - acc: 0.9958 - val_loss: 0.1028 - val_acc: 0.9956\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0793 - acc: 0.9953 - val_loss: 0.1231 - val_acc: 0.9956\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0777 - acc: 0.9939 - val_loss: 0.1194 - val_acc: 0.9911\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0746 - acc: 0.9953 - val_loss: 0.1129 - val_acc: 0.9926\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0741 - acc: 0.9958 - val_loss: 0.0886 - val_acc: 0.9956\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0717 - acc: 0.9949 - val_loss: 0.1214 - val_acc: 0.9926\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0700 - acc: 0.9953 - val_loss: 0.1178 - val_acc: 0.9926\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0684 - acc: 0.9953 - val_loss: 0.1113 - val_acc: 0.9956\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0671 - acc: 0.9958 - val_loss: 0.1081 - val_acc: 0.9911\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0662 - acc: 0.9949 - val_loss: 0.0877 - val_acc: 0.9956\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0647 - acc: 0.9958 - val_loss: 0.1104 - val_acc: 0.9956\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0633 - acc: 0.994 - 0s 15ms/step - loss: 0.0633 - acc: 0.9944 - val_loss: 0.0850 - val_acc: 0.9926\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0626 - acc: 0.9949 - val_loss: 0.0679 - val_acc: 0.9956\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0632 - acc: 0.9949 - val_loss: 0.0670 - val_acc: 0.9941\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0629 - acc: 0.9949 - val_loss: 0.0753 - val_acc: 0.9970\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0619 - acc: 0.9949 - val_loss: 0.0710 - val_acc: 0.9956\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0600 - acc: 0.9953 - val_loss: 0.0607 - val_acc: 0.9970\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0561 - acc: 0.9958 - val_loss: 0.0648 - val_acc: 0.9970\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0582 - acc: 0.9944 - val_loss: 0.0627 - val_acc: 0.9970\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0572 - acc: 0.9953 - val_loss: 0.0795 - val_acc: 0.9956\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0562 - acc: 0.9958 - val_loss: 0.0761 - val_acc: 0.9911\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0549 - acc: 0.9953 - val_loss: 0.0588 - val_acc: 0.9970\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0543 - acc: 0.9953 - val_loss: 0.0552 - val_acc: 0.9970\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0522 - acc: 0.9953 - val_loss: 0.0542 - val_acc: 0.9956\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0518 - acc: 0.9958 - val_loss: 0.0586 - val_acc: 0.9956\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0523 - acc: 0.9944 - val_loss: 0.0532 - val_acc: 0.9970\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0521 - acc: 0.9944 - val_loss: 0.0577 - val_acc: 0.9926\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0519 - acc: 0.9949 - val_loss: 0.0543 - val_acc: 0.9970\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0503 - acc: 0.9953 - val_loss: 0.0511 - val_acc: 0.9941\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0477 - acc: 0.9958 - val_loss: 0.0485 - val_acc: 0.9970\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0475 - acc: 0.9958 - val_loss: 0.0476 - val_acc: 0.9970\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0489 - acc: 0.9958 - val_loss: 0.0520 - val_acc: 0.9956\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0476 - acc: 0.9949 - val_loss: 0.0497 - val_acc: 0.9956\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0462 - acc: 0.9958 - val_loss: 0.0444 - val_acc: 0.9956\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0492 - acc: 0.9949 - val_loss: 0.0535 - val_acc: 0.9926\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0460 - acc: 0.9949 - val_loss: 0.0433 - val_acc: 0.9970\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0479 - acc: 0.9939 - val_loss: 0.0489 - val_acc: 0.9956\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0469 - acc: 0.9944 - val_loss: 0.0448 - val_acc: 0.9956\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0457 - acc: 0.9958 - val_loss: 0.0446 - val_acc: 0.9956\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0429 - acc: 0.9953 - val_loss: 0.0432 - val_acc: 0.9956\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.0490 - acc: 0.9944 - val_loss: 0.0452 - val_acc: 0.9956\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0442 - acc: 0.9958 - val_loss: 0.0429 - val_acc: 0.9956\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0421 - acc: 0.9949 - val_loss: 0.0383 - val_acc: 0.9970\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0438 - acc: 0.9944 - val_loss: 0.0401 - val_acc: 0.9956\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0444 - acc: 0.9939 - val_loss: 0.0416 - val_acc: 0.9970\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0418 - acc: 0.9935 - val_loss: 0.0562 - val_acc: 0.9956\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0445 - acc: 0.9953 - val_loss: 0.0371 - val_acc: 0.9985\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0410 - acc: 0.9963 - val_loss: 0.0408 - val_acc: 0.9956\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0423 - acc: 0.9958 - val_loss: 0.0437 - val_acc: 0.9956\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0414 - acc: 0.9958 - val_loss: 0.0495 - val_acc: 0.9941\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0410 - acc: 0.9949 - val_loss: 0.0464 - val_acc: 0.9956\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0389 - acc: 0.9953 - val_loss: 0.0372 - val_acc: 0.9970\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0403 - acc: 0.9958 - val_loss: 0.0459 - val_acc: 0.9956\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0417 - acc: 0.9953 - val_loss: 0.0429 - val_acc: 0.9970\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0401 - acc: 0.9949 - val_loss: 0.0425 - val_acc: 0.9956\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0436 - acc: 0.9930 - val_loss: 0.0489 - val_acc: 0.9970\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0393 - acc: 0.9958 - val_loss: 0.1169 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0385 - acc: 0.9963 - val_loss: 0.0462 - val_acc: 0.9970\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0380 - acc: 0.9953 - val_loss: 0.0392 - val_acc: 0.9970\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0373 - acc: 0.9967 - val_loss: 0.0383 - val_acc: 0.9970\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0378 - acc: 0.9953 - val_loss: 0.0372 - val_acc: 0.9956\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0375 - acc: 0.9958 - val_loss: 0.0427 - val_acc: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27cf1d69a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), shuffle=True, batch_size=128, callbacks=[early_stopping,reduceLR_cb], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9653e525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0371 - acc: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03713151440024376, 0.9985228776931763]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5349bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc2f4ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[358,   0],\n",
       "       [  1, 318]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(np.argmax(y_test,-1), np.argmax(preds,-1))\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "980d57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, title='CONFUSION MATRIX', cmap=plt.cm.Reds):\n",
    "    target_names=['Legit','Fake']\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c4dfc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a028a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/classifier_2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
